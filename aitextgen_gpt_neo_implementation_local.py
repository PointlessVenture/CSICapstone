# -*- coding: utf-8 -*-
"""aitextgen GPT-NEO Implementation
Automatically generated by Colaboratory.
Original file is located at
    https://colab.research.google.com/drive/1WPgw7I9al9ndt3v7vy7kFp4Rn3uYuVjG
"""

# Starter imports/setup

# !pip install -q aitextgen
import language_tool_python
import text2emotion
import nltk
from azure.cognitiveservices.vision.computervision import ComputerVisionClient
from azure.cognitiveservices.vision.computervision.models import OperationStatusCodes
from azure.cognitiveservices.vision.computervision.models import VisualFeatureTypes
from msrest.authentication import CognitiveServicesCredentials
import time
import re
import requests
import logging
logging.basicConfig(
        format="%(asctime)s — %(levelname)s — %(name)s — %(message)s",
        datefmt="%m/%d/%Y %H:%M:%S",
        level=logging.INFO
    )

def compVision():
    keyFile = open('keys.txt', 'r')
    keyLines = keyFile.readlines()

    AZURE_API_KEY = keyLines[0].rstrip()
    AZURE_API_ENDPOINT = keyLines[1].rstrip()
    REDDIT_CLIENT_ID = keyLines[2].rstrip()
    REDDIT_SECRET_TOKEN = keyLines[3].rstrip()
    REDDIT_UN = keyLines[4].rstrip()
    REDDIT_PW = keyLines[5].rstrip()

    # note that CLIENT_ID refers to 'personal use script' and SECRET_TOKEN to 'token'
    auth = requests.auth.HTTPBasicAuth(REDDIT_CLIENT_ID, REDDIT_SECRET_TOKEN)

    # here we pass our login method (password), username, and password
    data = {'grant_type': 'password',
            'username': REDDIT_UN,
            'password': REDDIT_PW}

    # setup our header info, which gives reddit a brief description of our app
    headers = {'User-Agent': 'ComplimentBot/0.0.1'}

    # send our request for an OAuth token
    res = requests.post('https://www.reddit.com/api/v1/access_token',
                        auth=auth, data=data, headers=headers)

    # convert response to JSON and pull access_token value
    TOKEN = res.json()['access_token']

    # add authorization to our headers dictionary
    headers['Authorization'] = f'bearer {TOKEN}'

    # while the token is valid (~2 hours) we just add headers=headers to our requests
    print(headers)

    allposts = requests.get('https://oauth.reddit.com/r/FreeCompliments/hot', headers=headers)
    image = ''
    for post in allposts.json()['data']['children']:
             #print("Looking at Posts!")
             #Output all Keys to see available data.
             link = post['data']['url']
             if 'com' in link:
                 continue
             else:
                  if 'jpg' in link:
                     #print("Found an Image!")
                     image = link
                  else:
                      continue

    print(image)
    computerVision = ComputerVisionClient(AZURE_API_ENDPOINT, CognitiveServicesCredentials(AZURE_API_KEY))
    output = ""
    response = computerVision.describe_image(url=image, raw=True)
    #for tag in response.output.tags:
        #output += tag
        #output += ", "
    for caption in response.output.captions:
        output += caption.text
    detect = computerVision.detect_objects(image)
    #for obj in detect.objects:
       # print(obj.object_property, obj.rectangle)
    return output

def generation(ai, output):

    text = ai.generate_one(
            batch_size=5,
            prompt=("Generate a compliment for " + output + ": \n"),
            max_length=45,
            temperature=0.7,
            top_p=0.9)

    return text


def checkGrammar(allCompliments):
    tool = language_tool_python.LanguageTool('en-US')
    lenList = []
    bestCompliments = []

    # Grab the list of the lengths of all compliments in order
    for comp in allCompliments:
        matches = tool.check(comp)
        lenList.append(len(matches))

    # Grab the three most grammatically correct compliments
    for x in range(3):
        bestScore = 100
        bestIndex = -1
        # Get the index of compliment with least errors
        for y in range(len(lenList)):
            if lenList[y] < bestScore:
                bestScore = lenList[y]
                bestIndex = y

        bestCompliments.append(allCompliments[bestIndex])
        # So this never gets selected again
        lenList[bestIndex] = 101

    mostHappy = -1
    bestCompliment = ""
    for i in bestCompliments:
        emotionScores = text2emotion.get_emotion(i)
        if emotionScores['Happy'] > mostHappy:
            mostHappy = emotionScores['Happy']
            bestCompliment = i

    return bestCompliment
